---
#name: amba-analysis-stream

version: "3"

services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    restart: unless-stopped
    hostname: zookeeper
    networks:
      - backend


  kafka:
    image: wurstmeister/kafka:latest
    container_name: kafka
    restart: unless-stopped
    depends_on:
      - zookeeper
    hostname: kafka
    links:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: ${KAFKA_BROKER_ID}
      KAFKA_CREATE_TOPICS: "${KAFKA_CREATE_TOPICS}"
      KAFKA_ADVERTISED_HOST_NAME: "${KAFKA_ADVERTISED_HOST_NAME}"
      KAFKA_ZOOKEEPER_CONNECT: "${KAFKA_ZOOKEEPER_CONNECT}"
      KAFKA_ADVERTISED_PORT: "${KAFKA_ADVERTISED_PORT}"
      KAFKA_ADVERTISED_LISTENERS: "${KAFKA_ADVERTISED_LISTENERS_PREFIX}${KAFKA_BOOTRSTRAP_SERVER}"
    networks:
      - backend


  mongo_db:
    image: mongo:5.0.2
    container_name: mongo_db
    ports:
      - "${MONGO_PORT}"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
      MONGO_INITDB_DATABASE: ${MONGO_INITDB_DATABASE}
    networks:
      - backend

#    volumes:
#        - ./mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
# create this file temporary during github workflow

  connector_twitter:
    image: ghcr.io/ambalytics/amba-connector-twitter/amba-connector-twitter:latest
    container_name: connector_twitter
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
      BERARER_TOKEN: ${TWITTER_BEARER_TOKEN}
    networks:
      - backend

  perculator:
    image: ghcr.io/ambalytics/amba-analysis-worker-perculator/amba-analysis-worker-perculator:latest
    container_name: perculator
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 100M
    restart: unless-stopped
    depends_on:
      - connector_twitter
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend

  worker_twitter:
    image: ghcr.io/ambalytics/amba-analysis-worker-discussion/amba-analysis-worker-twitter:latest
    container_name: worker_twitter
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 100M
    restart: unless-stopped
    depends_on:
      - connector_twitter
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend

# only for debug, mongo only left for publications at the moment
#  connector_mongodb:
#    image: mongodb-connector
#    container_name: mongodb-connector
#    depends_on:
#      - mongo_db
#    environment:
#      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
#    networks:
#      - backend

  worker_pubfinder: # --build for restart
    image: ghcr.io/ambalytics/amba-analysis-worker-pubfinder/amba-analysis-worker-pubfinder:latest # -t for building
    container_name: worker_pubfinder
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 100M
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend

  aggregator:
    image: ghcr.io/ambalytics/amba-analysis-worker-aggregator/amba-analysis-worker-aggregator:latest
    container_name: aggregator
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend

  api:
    image: ghcr.io/ambalytics/amba-analysis-streams-api/amba-analysis-streams-api:latest
    container_name: api
    restart: unless-stopped
    ports:
      - "${API_PORT}"
    depends_on:
      - kafka
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend


  postgres:
    image: postgres
    restart: unless-stopped
    container_name: postgres
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT}:${POSTGRES_PORT}"
    networks:
      - backend
    volumes:
      - ./db:/docker-entrypoint-initdb.d/


  adminer:
    image: adminer
    container_name: adminer
    restart: unless-stopped
    ports:
      - "${ADMINER_PORT}"
    networks:
      - backend

  webserver:
    image: nginx:1.15.12-alpine
    container_name: webserver
    restart: unless-stopped
    volumes:
      - ./nginx/conf.d:/etc/nginx/conf.d
      - ./certbot/conf:/etc/nginx/ssl
      - ./certbot/data:/var/www/certbot
    ports:
      - "80:80"
      - "443:443"
    environment:
      - PHP_MEMORY_LIMIT=256M

  certbot:
    depends_on:
      - webserver
    image: certbot/dns-route53:latest
    container_name: certbot
    volumes:
      # we save our directory of keys on our host server
      - ./certbot/conf:/etc/letsencrypt
      - ./certbot/logs:/var/log/letsencrypt
    # command: certonly --dns-route53 --email it@ambalytics.com --agree-tos --no-eff-email -d api-analysis.ambalytics.com
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      -

networks:
  backend:
    driver: bridge
