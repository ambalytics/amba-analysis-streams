---
#name: amba-analysis-stream

services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    hostname: zookeeper
    networks:
      - backend


  kafka:
    image: wurstmeister/kafka:latest
    container_name: kafka
    depends_on:
      - zookeeper
    hostname: kafka
    links:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: ${KAFKA_BROKER_ID}
      KAFKA_CREATE_TOPICS: "${KAFKA_CREATE_TOPICS}"
      KAFKA_ADVERTISED_HOST_NAME: "${KAFKA_ADVERTISED_HOST_NAME}"
      KAFKA_ZOOKEEPER_CONNECT: "${KAFKA_ZOOKEEPER_CONNECT}"
      KAFKA_ADVERTISED_PORT: "${KAFKA_ADVERTISED_PORT}"
      KAFKA_ADVERTISED_LISTENERS: "${KAFKA_ADVERTISED_LISTENERS_PREFIX}${KAFKA_BOOTRSTRAP_SERVER}"
    networks:
      - backend


  mongo_db:
    image: mongo
    container_name: mongo-db
    ports:
      - "${MONGO_PORT}"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
      MONGO_INITDB_DATABASE: ${MONGO_INITDB_DATABASE}
    networks:
      - backend

#    volumes:
#        - ./mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
# create this file temporary during github workflow

  connector_twitter:
    image: twitter-connector
    container_name: twitter-connector
    depends_on:
      - kafka
    environment:
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
      BERARER_TOKEN: ${secrets.TWITTER_BEARER_TOKEN}
    networks:
      - backend

  perculator:
    image: twitter-perculator
    container_name: twitter-perculator
    cpus: 0.5
    mem_limit: 1g
    depends_on:
      - connector_twitter
    environment:
#      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
#      POSTGRES_USER: ${POSTGRES_USER}
#      POSTGRES_DB: ${POSTGRES_DB}
#      POSTGRES_HOST: ${POSTGRES_HOST}
#      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend

  worker_twitter:
    image: twitter-worker
    container_name: twitter-worker
    cpus: 0.5
    depends_on:
      - connector_twitter
    environment:
#      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
#      POSTGRES_USER: ${POSTGRES_USER}
#      POSTGRES_DB: ${POSTGRES_DB}
#      POSTGRES_HOST: ${POSTGRES_HOST}
#      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend

  connector_mongodb:
    image: mongodb-connector
    container_name: mongodb-connector
    depends_on:
      - mongo_db
    environment:
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend

  worker_pubfinder: # --build for restart
    image: pubfinder-worker # -t for building
    container_name: pubfinder-worker
    mem_limit: 1g
    depends_on:
      - kafka
    environment:
#      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
#      POSTGRES_USER: ${POSTGRES_USER}
#      POSTGRES_DB: ${POSTGRES_DB}
#      POSTGRES_HOST: ${POSTGRES_HOST}
#      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend

  aggregator:
    image: aggregator
    container_name: aggregator
    depends_on:
      - kafka
    environment:
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend

  api:
    image: api
    container_name: api
    ports:
      - "${API_PORT}"
    depends_on:
      - kafka
    environment:
#      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
#      POSTGRES_USER: ${POSTGRES_USER}
#      POSTGRES_DB: ${POSTGRES_DB}
#      POSTGRES_HOST: ${POSTGRES_HOST}
#      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend


#  postgres:
#    image: postgres
##    restart: always
#    container_name: postgres
#    environment:
#      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
#      POSTGRES_USER: ${POSTGRES_USER}
#      POSTGRES_DB: ${POSTGRES_DB}
#    ports:
#      - "${POSTGRES_PORT}:${POSTGRES_PORT}"
#    networks:
#      - backend
#    volumes:
#      - ./db:/docker-entrypoint-initdb.d/
#
#  adminer:
#    image: adminer
#    container_name: adminer
##    restart: always
#    ports:
#      - "${ADMINER_PORT}"
#    networks:
#      - backend

networks:
  backend:
    driver: bridge

# todo kafka topics
# https://docs.docker.com/compose/compose-file/compose-file-v3/#healthcheck
# for better waiting
# processed <-> aggregated need same amount of partitions for faust to work
#
# topicname:partition:replica
# "events_unlinked:1:1, events_unlinked-discussed:3:1, events_unlinked-crossref:3:1, events_linked:1:1, events_linked-discussed:3:1, events_unknown:3:1, events_processed:1:1, events_processed-discussed:3:1, events_aggregated:1:1"