---
#name: amba-analysis-stream

services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    restart: unless-stopped
    hostname: zookeeper
    networks:
      - backend


  kafka:
    image: wurstmeister/kafka:latest
    container_name: kafka
    restart: unless-stopped
    depends_on:
      - zookeeper
    hostname: kafka
    links:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: ${KAFKA_BROKER_ID}
      KAFKA_CREATE_TOPICS: "${KAFKA_CREATE_TOPICS}"
      KAFKA_ADVERTISED_HOST_NAME: "${KAFKA_ADVERTISED_HOST_NAME}"
      KAFKA_ZOOKEEPER_CONNECT: "${KAFKA_ZOOKEEPER_CONNECT}"
      KAFKA_ADVERTISED_PORT: "${KAFKA_ADVERTISED_PORT}"
      KAFKA_ADVERTISED_LISTENERS: "${KAFKA_ADVERTISED_LISTENERS_PREFIX}${KAFKA_BOOTRSTRAP_SERVER}"
    networks:
      - backend


  mongo_db:
    image: mongo
    container_name: mongo_db
    ports:
      - "${MONGO_PORT}"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
      MONGO_INITDB_DATABASE: ${MONGO_INITDB_DATABASE}
    networks:
      - backend

#    volumes:
#        - ./mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
# create this file temporary during github workflow

  connector_twitter:
    image: connector_twitter
    container_name: connector_twitter
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
      BERARER_TOKEN: ${TWITTER_BEARER_TOKEN}
    networks:
      - backend

  perculator:
    image: perculator
    container_name: perculator
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 100M
    restart: unless-stopped
    depends_on:
      - connector_twitter
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend

  worker_twitter:
    image: worker_twitter
    container_name: worker_twitter
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 100M
    restart: unless-stopped
    depends_on:
      - connector_twitter
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend

# only for debug, mongo only left for publications at the moment
#  connector_mongodb:
#    image: mongodb-connector
#    container_name: mongodb-connector
#    depends_on:
#      - mongo_db
#    environment:
#      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
#    networks:
#      - backend

  worker_pubfinder: # --build for restart
    image: worker_pubfinder # -t for building
    container_name: worker_pubfinder
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 100M
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend

  aggregator:
    image: aggregator
    container_name: aggregator
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend

  api:
    image: api
    container_name: api
    restart: unless-stopped
    ports:
      - "${API_PORT}"
    depends_on:
      - kafka
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
    networks:
      - backend


  postgres:
    image: postgres
    restart: unless-stopped
    container_name: postgres
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT}:${POSTGRES_PORT}"
    networks:
      - backend
    volumes:
      - ./db:/docker-entrypoint-initdb.d/

  adminer:
    image: adminer
    container_name: adminer
    restart: unless-stopped
    ports:
      - "${ADMINER_PORT}"
    networks:
      - backend

networks:
  backend:
    driver: bridge

# todo kafka topics
# https://docs.docker.com/compose/compose-file/compose-file-v3/#healthcheck
# for better waiting
# processed <-> aggregated need same amount of partitions for faust to work
#
# topicname:partition:replica
# "events_unlinked:1:1, events_unlinked-discussed:3:1, events_unlinked-crossref:3:1, events_linked:1:1, events_linked-discussed:3:1, events_unknown:3:1, events_processed:1:1, events_processed-discussed:3:1, events_aggregated:1:1"