---
#name: amba-analysis-stream

services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    restart: unless-stopped
    hostname: zookeeper
    networks:
      - backend


  kafka:
    image: wurstmeister/kafka:latest
    container_name: kafka
    restart: unless-stopped
    depends_on:
      - zookeeper
    hostname: kafka
    links:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: ${KAFKA_BROKER_ID}
      KAFKA_CREATE_TOPICS: "${KAFKA_CREATE_TOPICS}"
      KAFKA_ADVERTISED_HOST_NAME: "${KAFKA_ADVERTISED_HOST_NAME}"
      KAFKA_ZOOKEEPER_CONNECT: "${KAFKA_ZOOKEEPER_CONNECT}"
      KAFKA_ADVERTISED_PORT: "${KAFKA_ADVERTISED_PORT}"
      KAFKA_ADVERTISED_LISTENERS: "${KAFKA_ADVERTISED_LISTENERS_PREFIX}${KAFKA_BOOTRSTRAP_SERVER}"
    networks:
      - backend

  connector_twitter:
    image: connector_twitter
    container_name: connector_twitter
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
      TWITTER_BEARER_TOKEN: ${TWITTER_BEARER_TOKEN}
      SENTRY_DSN: 'https://36b75f4025a54ef1ade6069d311dc0c1@apm.ambalytics.com/8'
      SENTRY_TRACES_SAMPLE_RATE: 1.0
    networks:
      - backend

  perculator:
    image: perculator
    container_name: perculator
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 100M
    restart: unless-stopped
    depends_on:
      - connector_twitter
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
      SENTRY_DSN: 'https://ce9c4c51fbe842cca7c8736cc33e50b6@apm.ambalytics.com/9'
      SENTRY_TRACES_SAMPLE_RATE: 1.0
    networks:
      - backend

  worker_twitter:
    image: worker_twitter
    container_name: worker_twitter
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 100M
    restart: unless-stopped
    depends_on:
      - connector_twitter
      - kafka
      - postgres
      - influxdb
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
      SENTRY_DSN: 'https://a6c6f9c04b38487e8d85f2b0e22cb7df@apm.ambalytics.com/7'
      SENTRY_TRACES_SAMPLE_RATE: 1.0
    networks:
      - backend

  worker_pubfinder: # --build for restart
    image: worker_pubfinder # -t for building
    container_name: worker_pubfinder
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 100M
    restart: unless-stopped
    depends_on:
      - kafka
      - postgres
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
      SENTRY_DSN: 'https://f0dfcffd7b53402eb4733e76dad63212@apm.ambalytics.com/10'
      SENTRY_TRACES_SAMPLE_RATE: 1.0
    networks:
      - backend

  aggregator:
    image: aggregator
    container_name: aggregator
#    restart: unless-stopped
    depends_on:
      - kafka
      - postgres
      - influxdb
    environment:
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      INFLUXDB_V2_TOKEN: ${INFLUXDB_TOKEN}
      INFLUXDB_V2_ORG: ${INFLUXDB_ORG}
      INFLUXDB_V2_URL: 'http://influxdb:8086'
      INFLUXDB_V2_TIMEOUT: 60000
      INFLUXDB_BUCKET: ${INFLUXDB_BUCKET}
      INFLUXDB_PORT: ${INFLUXDB_PORT}
      CONSUMER_KEY_TWITTER_BOT: ${CONSUMER_KEY_TWITTER_BOT}
      CONSUMER_SECRET_TWITTER_BOT: ${CONSUMER_SECRET_TWITTER_BOT}
      ACCESS_TOKEN_TWITTER_BOT: ${ACCESS_TOKEN_TWITTER_BOT}
      ACCESS_TOKEN_SECRET_TWITTER_BOT: ${ACCESS_TOKEN_SECRET_TWITTER_BOT}
      SENTRY_DSN: 'https://87d01729e9be480c8d9b80a8a4d57f58@apm.ambalytics.com/12'
      SENTRY_TRACES_SAMPLE_RATE: 1.0
    networks:
      - backend


  api:
    image: api
    container_name: api
    restart: unless-stopped
    ports:
      - "${API_PORT}"
    depends_on:
      - kafka
      - postgres
      - influxdb
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      KAFKA_BOOTRSTRAP_SERVER: ${KAFKA_BOOTRSTRAP_SERVER}
      INFLUXDB_V2_TOKEN: ${INFLUXDB_TOKEN}
      INFLUXDB_V2_ORG: ${INFLUXDB_ORG}
      INFLUXDB_V2_URL: 'http://influxdb:8086'
      INFLUXDB_BUCKET: ${INFLUXDB_BUCKET}
      INFLUXDB_PORT: ${INFLUXDB_PORT}
      SENTRY_DSN: 'https://8f472f79cae545f9994a56a0e0bebf1c@apm.ambalytics.com/11'
      SENTRY_TRACES_SAMPLE_RATE: 1.0
    networks:
      - backend


  postgres:
    image: postgres
    restart: unless-stopped
    container_name: postgres
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT}:${POSTGRES_PORT}"
    networks:
      - backend
    volumes:
      - ./db:/docker-entrypoint-initdb.d/

  adminer:
    image: adminer
    container_name: adminer
    restart: unless-stopped
    ports:
      - "${ADMINER_PORT}"
    networks:
      - backend

  influxdb:
    image: influxdb:2.0.8
    container_name: influxdb
    restart: unless-stopped
    ports:
      - "${INFLUXDB_PORT}:${INFLUXDB_PORT}"
    environment:
      DOCKER_INFLUXDB_INIT_MODE: "setup"
      DOCKER_INFLUXDB_INIT_USERNAME: ${INFLUXDB_USER}
      DOCKER_INFLUXDB_INIT_PASSWORD: ${INFLUXDB_PASSWORD}
      DOCKER_INFLUXDB_INIT_ORG: ${INFLUXDB_ORG}
      DOCKER_INFLUXDB_INIT_BUCKET: ${INFLUXDB_BUCKET}
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: ${INFLUXDB_TOKEN}
      INFLUXD_STORAGE_CACHE_MAX_MEMORY_SIZE: 3073741824
    networks:
      - backend

networks:
  backend:
    driver: bridge

# todo kafka topics
# https://docs.docker.com/compose/compose-file/compose-file-v3/#healthcheck
# for better waiting
# processed <-> aggregated need same amount of partitions for faust to work
#
# topicname:partition:replica
# "events_unlinked:1:1, events_unlinked-discussed:3:1, events_unlinked-crossref:3:1, events_linked:1:1, events_linked-discussed:3:1, events_unknown:3:1, events_processed:1:1, events_processed-discussed:3:1, events_aggregated:1:1"